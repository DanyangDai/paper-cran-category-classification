---
title: "Cranlog analysis"
author: "Danyang Dai"
date: "03/08/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(rvest)
library(glue)
library(feasts)
library(cranlogs)
library(plotly)
library(scales)
library(lubridate)
```

```{r , cache=TRUE, message=FALSE,  results=FALSE, warning=FALSE, comment=FALSE}

load(here::here("data/derived/spilk_2014.RData"))
load(here::here("data/derived/total_downloads.RData"))

country_2014 <- spilk_2014 %>%
  group_by(country) %>%
  count()

ID_2014 <- spilk_2014 %>%
  group_by(country, ip_id) %>%
  count()

pkg_ID_2014 <- spilk_2014 %>%
  group_by(country, ip_id, package) %>%
  count()

ido <- max(ID_2014$n) / sum(ID_2014$n)


download_141116 <- total_downloads %>%
  filter(date == "2014-11-16")

download_141118 <- total_downloads %>%
  filter(date == "2014-11-18")


spilk_2014 %>%
  mutate(obsid = paste(country, ip_id, package)) %>%
  pull(obsid) %>%
  n_distinct()

```

```{r, cache=TRUE, message=FALSE,  results=FALSE, warning=FALSE, comment=FALSE}
load(here::here("data/derived/spilk_2018.RData"))

country_2018 <- spilk_2018 %>%
  group_by(country) %>%
  count()

ID_2018 <- spilk_2018 %>%
  group_by(country, ip_id) %>%
  count()

pkg_ID_18 <- spilk_2018 %>%
  group_by(country, ip_id, package) %>%
  count()


top15 <- pkg_ID_18[pkg_ID_18$n %in% tail(sort(pkg_ID_18$n), 15), ]

us_18 <- top15 %>%
  group_by(country, package) %>%
  summarise(n = sum(n))

```

Testing whether the package rank could remove the bots download: 

```{r}
library(packageRank)
packageLog(package = "forecast", date = "2015-10-20")[8:14, -(4:6)]
tidyverse_2018 <- packageLog(package = "tidyverse", date = "2018-10-21")
filteredDownloads(package = "forecast", date = "2018-10-21")
filteredDownloads(package = "cholera", date = "2020-07-31")

```

It takes very long to run and did not get ideal results. For more information: <https://github.com/lindbrook/packageRank>


Trying to download the number of downloads for each pacakge in the past week, failed to do so. 
```{r}
library(cranlogs)
library(purrr)

n_package <- first_release %>%
  group_by(Date) %>%
  summarise(n = n_distinct(Package))

download_1 <- cran_downloads(packages = c(cran_names[1:100]), when = "last-week")
download_2 <- cran_downloads(packages = c(cran_names[101:200]), when = "last-week")
download_3 <- cran_downloads(packages = c(cran_names[201:300]), when = "last-week")

datalist <- list()

for (i in 26:175) {
  Sys.sleep(sample(1:10))
  download <- cran_downloads(packages = c(cran_names[((i - 1) * 100 + 1):i * 100]), when = "last-week")
  datalist[[i]] <- download # add it to your list
}


```


```{r}

# identify bot downloads 

bot_2014 <- spilk_2014 %>%
  group_by(country, ip_id, package, r_version, size) %>%
  count()

bot_2018 <- spilk_2018 %>%
  group_by(country, ip_id, package, r_version, size, time) %>%
  count()


entries_2012_1001_dir <- download_RStudio_CRAN_data(START = "2012-10-01", END = "2012-10-01", log_folder = "/Users/daidanyang/Documents/GitHub/paper-cran-category-classification/paper/Data")

# read .gz compressed files form local directory
entries_2012_1001 <- read.csv("~/Documents/GitHub/paper-cran-category-classification/paper/Data/2014-11-17.csv.gz")


bot_2012_1001 <- entries_2012_1001 %>%
  group_by(country, ip_id, package, r_version, size) %>%
  count()



entries_2012_1002_dir <- download_RStudio_CRAN_data(START = "2012-10-02", END = "2012-10-02", log_folder = "/Users/daidanyang/Documents/GitHub/paper-cran-category-classification/paper/Data")

# read .gz compressed files form local directory
entries_2012_1002 <- read.csv("~/Documents/GitHub/paper-cran-category-classification/paper/Data/2012-10-02.csv.gz")


bot_2012_1002 <- entries_2012_1002 %>%
  group_by(country, ip_id, package, r_version, size) %>%
  count()

entries_2021_0701_dir <- download_RStudio_CRAN_data(START = "2021-07-01", END = "2021-07-01", log_folder = "/Users/daidanyang/Documents/GitHub/paper-cran-category-classification/paper/Data")

# read .gz compressed files form local directory
entries_2021_0701 <- read.csv("~/Documents/GitHub/paper-cran-category-classification/paper/Data/2021-07-01.csv.gz")

bot_2021_0701 <- entries_2021_0701 %>%
  group_by(country, ip_id, package, r_version, size, time) %>%
  count()

```







```{r}
#Sampling a day in every month 
library(purrr)

start_date <- as.Date(seq(as.Date("2012-10-01"),length=106,by="months"))
end_date <- as.Date(seq(as.Date("2012-11-01"),length=106,by="months")-1)
time_frame <- data.frame(start = start_date,
                      end = end_date)


sample_date <- time_frame %>%
    rowwise() %>%
    mutate(random_date = sample(x = seq(from = start,
                                        to = end,
                                        by = "day"),
                                size = 1))
```


```{r}
#sampling a day in every 2 months 
start_date_2 <- as.Date(seq(as.Date("2012-10-01"),length=53,by="2 months"))
end_date_2 <- as.Date(seq(as.Date("2012-11-01"),length=53,by="2 months")-1)
time_frame_2 <- data.frame(start = start_date_2,
                      end = end_date_2)

sample_date_2 <- time_frame_2 %>%
    rowwise() %>%
    mutate(random_date = sample(x = seq(from = start,
                                        to = end,
                                        by = "day"),
                                size = 1))

sampling_dates <-  as.Date(sort(c(sample_date$random_date,sample_date_2$random_date)))

```



```{r}
csv_files <- list.files(path = "data/derived", pattern="\\.csv\\.gz$",
                        full.names = TRUE) 

data_12<- read_csv(head(csv_files, 5), id = "file")

process_data <- function(file) {
  read_csv(file) %>% 
    count(country, ip_id, package, version, size, date) %>% 
    write_csv(file.path(dirname(file), "..", "processed", basename(file)))
}




csv_files %>% lapply(process_data)

bot_2012 <- data_12 %>% 
  group_by(date,time,country, ip_id, package, version, size) %>%
  count() %>% 
  sort(n)

bot_2012_wotime <- data_12 %>% 
  group_by(date,country, ip_id, package, version, size) %>%
  count()

```




```{r}
data_13<- read_csv(csv_files[6:23], id = "file")

bot_2013 <- data_13 %>% 
  group_by(date,time,country, ip_id, package, version, size) %>%
  count()


bot_2013_wotime <- data_13 %>% 
  group_by(date,country, ip_id, package, version, size) %>%
  count()

```


```{r}
data_14<- read_csv(csv_files[24:42], id = "file")

bot_2014 <- data_14 %>% 
  group_by(date,time,country, ip_id, package, version, size) %>%
  count()


bot_2014_wotime <- data_14 %>% 
  group_by(date,country, ip_id, package, version, size) %>%
  count()

```

```{r}
data_15<- read_csv(csv_files[43:61], id = "file")

bot_2015 <- data_15 %>% 
  group_by(date,time,country, ip_id, package, version, size) %>%
  count()


bot_2015_wotime <- data_15 %>% 
  group_by(date,country, ip_id, package, version, size) %>%
  count() %>% 


```

```{r}
data_16<- read_csv(csv_files[62:80], id = "file")

bot_2016 <- data_16 %>% 
  group_by(date,time,country, ip_id, package, version, size) %>%
  count()


bot_2016_wotime <- data_16 %>% 
  group_by(date,country, ip_id, package, version, size) %>%
  count() 

```


