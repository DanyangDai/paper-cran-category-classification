---
title: Extracting package information 
output: html_document
---


```{r all_pkgs}
library(tidyverse)
library(lubridate)
library(rvest)
library(glue)
library(dplyr)
library(purrr)
library(ggplot2)
library(feasts)
library(cranlogs)
library(stringr)
library(installr)
library(plotly)
library(scales)

```

```{r}
url <- "http://cran.rstudio.com/web/packages/packages.rds"
db <- readRDS(url(url)) %>% 
  as.data.frame()%>% 
  mutate(Description = str_replace_all(Description, "\n", " "),
         Description = str_squish(Description),
         Title = str_replace_all(Title, "\n", " "))
```


```{r remove-same-authors}
n_pkgs <-nrow(db)
author<-distinct(db,Author,.keep_all= TRUE)
nrow(author)

nonr_author<-sapply(strsplit(as.character(author$Author), " \\(") , "[" , 1) 

#getting all the RStudio copyright ownership
rstudio<- str_detect(author$Author, "RStudio") %>% 
  sum(na.rm = TRUE)


# non-RStudio ownership
pkg_rstusio <- db %>%
  filter(grepl('RStudio', Author)) %>%
  select(Package) 


# filter the packages whose author is from R core group
pkg_core <- db %>%
  filter(grepl('Douglas Bates|John Chambers|Peter Dalgaard|Robert Gentleman|Kurt Hornik|Ross Ihaka|Tomas Kalibera|Michael Lawrence|Friedrich Leisch|Uwe Ligges|Thomas Lumley|Martin Maechler|Martin Morgan|Paul Murrell|Brian Ripley|Deepayan Sarkar|Duncan Temple Lang|Luke Tierney|Simon Urbanek|Martyn Plummer|', Author)) %>%
  select(Package)

# filter the packages whose author is on R secondary group
pkg_secondary <- db %>%
  filter(!grepl('Guido Masarotto|Duncan Murdoch|Henrik Bengtsson|Roger Bivand|Ben Bolker|David Brahm|Vince Carey|Saikat DebRoy|Matt Dowle|Dirk Eddelbuettel|Claus Ekstrom|John Fox|Paul Gilbert|Yu Gong|Gabor Grothendieck|Frank E Harrell Jr|Peter M. Haverty|Torsten Hothorn|Robert King|Kjetil Kjernsmo|Roger Koenker|Philippe Lambert|Jan de Leeuw|Jim Lindsey|Patrick Lindsey|Catherine Loader| Gordon Maclean|Arni Magnusson|John Maindonald|David Meyer|Ei-ji Nakama|Jens Oehlschägel|Steve Oncley|Richard O’Keefe|Hubert Palme|Roger D. Peng|José C. Pinheiro|Tony Plate|Anthony Rossini| Jonathan Rougier|Petr Savicky|Günther Sawitzki|Marc Schwartz|Arun Srinivasan|Detlef Steuer|Bill Simpson|Gordon Smyth|Adrian Trapletti|Terry Therneau|Rolf Turner|Bill Venables|Gregory R. Warnes| Andreas Weingessel|Morten Welinder|James Wettenhall|Simon Wood|and Achim Zeileis', Author)) %>%
  select(Package) 


pkg_r_related <- db %>%
  filter(stringr::str_detect(Author, 'Hadley Wickham|Yihui Xie|Gabor Csardi|Winston Chang|Andrie de Vries|Alison Presmanes Hill|Mara Averick|Cole Arendt|Daniel Falbel|Garrick Aden-Buie|Garrett Grolemund|Gary|Joe Cheng|Jennifer (Jenny) Bryan|Jim Hester|J.J. Allaire|Jonathan|Joshua Spiewak|Dan Buch|Richard Iannone|Ralf Stubner|Tyler Finethy|Melissa Barca|Kevin Ushey|Javier Luraschi|Karl Feinauer|Charles Teague|Maria Semple|adamconroy|Ricardo Andrade|Steve Nolen|Randy Lai|Jeffrey Horner|Jan Marvin Garbuszus|Justace Clutter|Josh Paulson|Mike Bessuille|Jeffrey Arnold|Paul Kaefer|Jim Hester|Dirk Schumacher|
Philipp A.|Fabian Mundt|Fabian Mundt|boB Rudis|Asher|Henrik Bengtsson|James Lamb|rich-rstudio|Andrie de Vries|Iñaki Ucar|Mark Brown|Hiroaki Yutani|Dean Attali|Matthias Mailänder|Bruno Tremblay|Ian|John Blischak|Chris von Csefalvay|Jeroen Ooms|
Daniel Gromer|Kirill Müller|Jan Gleixner|Alexander Grueneberg|Darío Hereñú|Aron Atkins|harupiko|Barret Schloerke|James Arnold|Giuseppe Casalicchio|Fredric Johansson|Curtis Kephart|reudismam|Jeff Allen|Yuri Niyazov|Sean Kross|Carl A. B. Pearson|
Peter Glerup Ericson|Diomidis Spinellis|Paul Menzel|Lincoln Mullen|Colin Gillespie|Masafumi Okada|Øystein Sørensen|Matthew Grogan|Scott Kostyshak|Marcus Kinsella|rhinopotamus|Daiki Katsuragawa|Michael Steinbaugh|Jari Karppinen|Roy Storey|Kristofer Rye|Erin|Ben Torvaney|Pol Mesalles|Sainath Adapa|Vladimir Panfilov|Christian Brueffer|Julien Barnier|') )%>%
  select(Package) 


```


An alternative way to get the CRAN R-package names.
```{r cran-names}
library(available)
cran_names <- rownames(available:::available_packages(repos = available:::default_cran_repos))
```

```{r}
# getting the total R packages download numbers from 1998
dd_start <- "2012-10-01"
dd_end <- Sys.Date() - 1

is_weekend <- function(date) {
  weekdays(date) %in% c("Saturday", "Sunday")
}

total_downloads <- cran_downloads(from = dd_start, to = dd_end) %>% 
  mutate(year = year(date),
         day = yday(date),
         weekend = is_weekend(date)) %>% 
  filter(row_number() <= n()-1)


# replace missing values with the nearest number 
total_downloads$count[total_downloads$count == 0] <- 21959



total_downloads %>%
  ggplot()  + geom_line(aes(date, count))+
  geom_smooth(aes(date, count),stat = "smooth") 
```




```{r  2014-11-17}
```{r , cache=TRUE, message=FALSE,  results=FALSE, warning=FALSE, comment=FALSE}
#spilk_2014_dir <- download_RStudio_CRAN_data(START = '2014-11-17',END = '2014-11-17', log_folder="/Users/daidanyang/Documents/GitHub/paper-cran-category-classification/paper/Data")

# read .gz compressed files form local directory
#spilk_2014 <- read.csv("~/Documents/GitHub/paper-cran-category-classification/paper/Data/2014-11-17.csv.gz")

#save(spilk_2014, file = "spilk_2014.RData")

load(here::here("paper/spilk_2014.RData"))

country_2014 <- spilk_2014 %>%  
  group_by(country) %>% 
  count()

ID_2014 <- spilk_2014 %>%  
  group_by(country,ip_id) %>% 
  count()

pkg_ID_2014 <- spilk_2014 %>%  
  group_by(country,ip_id,package) %>% 
  count()

ido <- max(ID_2014$n)/sum(ID_2014$n)


download_141116 <-total_downloads %>% 
  filter(date == "2014-11-16")

download_141118 <-total_downloads %>% 
  filter(date == "2014-11-18")


spilk_2014 %>% 
  mutate(obsid = paste(country, ip_id, package)) %>% 
  pull(obsid) %>% 
  n_distinct()

```

```{r , cache=TRUE, message=FALSE,  results=FALSE, warning=FALSE, comment=FALSE}

#spilk_2018_dir <- download_RStudio_CRAN_data(START = '2018-10-21',END = '2018-10-21', log_folder="/Users/daidanyang/Documents/GitHub/paper-cran-category-classification/paper/Data")

# read .gz compressed files form local directory
#spilk_2018 <- read_RStudio_CRAN_data(spilk_2018_dir)

#save(spilk_2018, file = "spilk_2018.RData")

load("~/Documents/GitHub/paper-cran-category-classification/paper/spilk_2018.RData")

country_2018 <- spilk_2018 %>%  
  group_by(country) %>% 
  count()

ID_2018 <- spilk_2018 %>%  
  group_by(country,ip_id) %>% 
  count()

pkg_ID_18 <- spilk_2018 %>%  
  group_by(country,ip_id,package) %>% 
  count()


top15 <- pkg_ID_18[pkg_ID_18$n %in% tail(sort(pkg_ID_18$n),15),]

us_18 <- top15 %>% 
  group_by(country,package) %>% 
   summarise(n = sum(n))



```





```{r user-conference}
# adding the userR conference date 

conference_dates <- tribble(
  ~ name, ~ date,
  "UseR", "2004-05-20",
  "UseR", "2006-06-15",
  "UseR", "2007-08-08",
  "UseR", "2008-08-14",
  "UseR", "2009-07-08",
  "UseR", "2010-07-20",
  "UseR", "2011-08-16",
  "UseR", "2012-06-12",
  "UseR", "2013-06-10",
  "UseR", "2014-06-30",
  "UseR", "2015-06-30",
  "UseR", "2016-06-27",
  "UseR", "2017-07-04",
  "UseR", "2018-07-10",
  "UseR", "2019-07-09",
  "UseR", "2020-07-07",
  "UseR", "2021-07-05",
  "RStudio", "2017-01-11",
  "RStudio", "2018-01-31",
  "RStudio", "2019-01-15",
  "RStudio", "2020-01-27",
  "RStudio", "2021-03-03",
)

UseR <- dplyr::filter(conference_dates,name == "UseR")
Rstudio <-dplyr::filter(conference_dates,name == "RStudio")

download_user <- total_downloads %>%
  ggplot()  + geom_line(aes(date, count)) +
  geom_vline(xintercept = as.numeric(as.Date(UseR$date)), linetype="dotted", 
                color = "blue", size=0.1)+
  geom_vline(xintercept = as.numeric(as.Date(Rstudio$date)), linetype="dotted", 
                color = "red", size=0.1) 
   
ggplotly(download_user,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")
```



```{r}
summary(total_downloads$count)
total_downloads %>%
  ggplot()  + geom_line(aes(date, log(total_downloads$count))) 
```





```{r}
# working days effect 
total_downloads %>% 
  as_tsibble(index = date) %>% 
  gg_subseries(count,period = "week")
```

```{r}
# STL decomposition of total R package downloads 
total_downloads %>% 
  as_tsibble(index = date) %>% 
  model(
    STL(log(count+1) ~ trend(window=77) +
        season("week", window="periodic"))
  ) %>%
  components() %>% 
  autoplot() +
  geom_vline(xintercept = as.numeric(as.Date(UseR$date)), linetype="dotted",color = "blue", size=0.1) +
  geom_vline(xintercept = as.numeric(as.Date(Rstudio$date)), linetype="dotted",color = "red", size=0.1) 



```



```{r package-updates}
# Getting all the updates data 
library(pkgsearch)
updates <-map_dfr(cran_names[1:1000], cran_package_history)
updates_2 <- map_dfr(cran_names[1001:3000], cran_package_history)
updates_3 <- map_dfr(cran_names[3001:4000], possibly(cran_package_history, NULL))
updates_4 <- map_dfr(cran_names[4001:6000], possibly(cran_package_history, NULL))
updates_5 <- map_dfr(cran_names[6001:8000], possibly(cran_package_history, NULL))
updates_6 <- map_dfr(cran_names[8001:10000], possibly(cran_package_history, NULL))
updates_7 <- map_dfr(cran_names[10001:12000], possibly(cran_package_history, NULL))
updates_8 <- map_dfr(cran_names[12001:14000], possibly(cran_package_history, NULL))
updates_9 <- map_dfr(cran_names[14000:17828], possibly(cran_package_history, NULL))

```


```{r}
updates_select <- updates_select %>% 
  mutate(Date=as.Date(updates_select$date))

### No. of packages in CRAN before 2010 June 
nrow(updates_select %>%  
    group_by(Package) %>% 
  filter (Date <="2010-06-30") %>% 
  filter(Version == max(Version)))

```


```{r}
# Select top 10 packages from last month 

top_downloads <- cran_top_downloads("last-month")

updates_top <- updates_select %>% 
  filter(Package %in% top_downloads$package)


downloads_top <- cran_downloads(from = "2014-01-01",to = "2021-07-05", package = top_downloads$package) 

downloads_top %>% 
  ggplot() + 
  geom_line(aes(date, count,col = package))
  


```

```{r}
# updates and ggplot2 downloads pattern 
ggplot2 <- downloads_top %>% 
  filter(package == "ggplot2") %>% 
  ggplot() + 
  geom_line(aes(date, count))+
  geom_vline(xintercept = updates_top$Date, linetype="dotted", color = "red",   
             size=0.1)

 ggplotly(ggplot2,dynamicTicks = TRUE) %>%
  layout(hovermode = "x") 
```

```{r}
# STL decomposition on ggplot 
STL_ggplot <- downloads_top %>% 
  filter(package == "ggplot2") %>% 
  as_tsibble(index = date) %>% 
  model(
    STL(log(count+1) ~ trend(window=NULL) +
        season("week", window="periodic"))
  ) %>%
  components() %>% 
  autoplot() +
  geom_vline(xintercept = updates_top$Date, linetype="dotted",color = "blue", size=0.1)

ggplotly(STL_ggplot,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")

```


```{r}
# updates and dplyr downloads pattern 

dplyr <- downloads_top %>% 
  filter(package == "dplyr") %>% 
  ggplot() + 
  geom_line(aes(date, count))+
  geom_vline(xintercept = updates_top$Date, linetype="dotted", color = "red",   
             size=0.1)

ggplotly(dplyr,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")
```
```{r}
# updates and tibble downloads pattern 

tibble <- downloads_top %>% 
  filter(package == "tibble") %>% 
  ggplot() + 
  geom_line(aes(date, count))+
  geom_vline(xintercept = updates_top$Date , linetype="dotted", color = "red",   
             size=0.1)

ggplotly(tibble,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")
```


```{r select_pkg_ver_date}
select_pkg_ver_date <- function(x) { 
      x %>%       
        select(Package,Version,date)
}
updates_list <- 
updates_select <- map_dfr(updates_list, select_pkg_ver_date)
```




```{r}
# non-RStudio packages updates

updates_forecast <- updates_select %>% 
  filter(Package == "forecast") %>% 
  filter(Date >= as.Date("2012-10-29"))


forecast_download <- cran_downloads(packages = "forecast",from = "2012-10-29", to = "2021-07-12")

forecast <- forecast_download %>% 
  ggplot() + 
  geom_line(aes(date, count))+
  geom_vline(xintercept = updates_forecast$Date , linetype="dotted", color = "red", size=0.1)+ 
  scale_x_date(limits = as.Date(c('2012-10-29','2021-07-12')))

ggplotly(forecast,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")

```


```{r}
STL_forecast <- forecast_download %>% 
  as_tsibble(index = date) %>% 
  model(
    STL(log(count+1) ~ trend(window=NULL) +
        season("week", window="periodic"))
  ) %>%
  components() %>% 
  autoplot() +
  geom_vline(xintercept = updates_forecast$Date, linetype="dotted",color = "blue", size=0.1)

ggplotly(STL_forecast,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")

```


```{r}
first_release <- updates_select %>% 
  group_by(Package) %>% 
  filter(Date == min(Date))

first_release %>%
  group_by(Date) %>%
  summarise(n = n_distinct(Package)) %>%
  ggplot()  + geom_line(aes(Date, n))+
  geom_smooth(aes(Date, n),stat = "smooth")


```

```{r}
library(cranlogs)
library(purrr)

n_package <-first_release %>%
  group_by(Date) %>%
  summarise(n = n_distinct(Package))

download_1 <- cran_downloads(packages= c(cran_names[1:100]),when = "last-week")
download_2 <- cran_downloads(packages= c(cran_names[101:200]),when = "last-week")
download_3 <- cran_downloads(packages= c(cran_names[201:300]),when = "last-week")

datalist <- list()

for(i in 2:175){
  Sys.time(sample(1:10))
  download <- cran_downloads(packages= c(cran_names[((i-1)*100+1):i*100]),when = "last-week")
  datalist[[i]] <-  download # add it to your list
}


```

```{r}
library(httr)
library(jsonlite)
base_url  <- "http://cranlogs.r-pkg.org/"
daily_url <- paste0(base_url, "downloads/daily/")
top_url   <- paste0(base_url, "top/")

get_downloads <- function (when = c("last-day", "last-week", "last-month"), count = 100) 
{
    when <- match.arg(when)
    req <- GET(paste0(top_url, when, "/", count))
    stop_for_status(req)
    r <- fromJSON(content(req, as = "text", encoding = "UTF-8"), 
        simplifyVector = FALSE)
    df <- data.frame(stringsAsFactors = FALSE, 
        package = vapply(r$downloads, "[[", "", "package"), count = as.integer(vapply(r$downloads, 
            "[[", "", "downloads")), from = as.Date(r$start), 
        to = as.Date(r$end))
    if (nrow(df) != count) {
        warning("Requested ", count, " packages, returned only ", 
            nrow(df))
    }
    df
}
```

```{r}

#getting the top 100 downloads for last month 

download_top100 <- get_downloads(when="last-month")

top_100 <- db %>% 
  mutate(Package = as.character(Package)) %>%
  filter(Package %in% download_top100$package )  %>%
  filter(!grepl('RStudio', Author)) %>%
  select(Package) 

# Non RStudio downloads 
top_nonrstudio <- download_top100 %>% 
  filter(package %in% top_100$Package )


updates_jsonlite <- updates_select %>% 
  filter(Package == "jsonlite") %>% 
  filter(Date >= as.Date("2012-10-29"))


jsonlite_download <- cran_downloads(packages = "jsonlite",from = "2013-12-04", to = "2021-07-12")

jsonlite <- jsonlite_download %>% 
  ggplot() + 
  geom_line(aes(date, count))+
  geom_vline(xintercept = updates_jsonlite$Date , linetype="dotted", color = "red", size=0.1)+ 
  scale_x_date(limits = as.Date(c('2013-12-04','2021-07-12')))

ggplotly(jsonlite,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")

```

```{r}
updates_glue <- updates_select %>% 
  filter(Package == "glue") %>% 
  filter(Date >= as.Date("2012-10-29"))


glue_download <- cran_downloads(packages = "glue",from = "2017-04-17", to = "2021-07-12")

glue <- glue_download %>% 
  ggplot() + 
  geom_line(aes(date, count))+
  geom_vline(xintercept = updates_glue$Date , linetype="dotted", color = "red", size=0.1) + scale_x_date(limits = as.Date(c('2017-04-17','2021-07-12')))

ggplotly(glue,dynamicTicks = TRUE) %>%
  layout(hovermode = "x")
```




```{r}
library(plotly)

plot_ly(x = n_package$Date, y =  n_package$n, mode = 'lines')
```





To get the list of packages for a particular CRAN task view:

```{r ctv}
doe_pkgs <- ctv:::.get_pkgs_from_ctv_or_repos("ExperimentalDesign", 
                                              repos = "http://cran.rstudio.com/")[[1]]
survey_pkgs <- ctv:::.get_pkgs_from_ctv_or_repos("OfficialStatistics", 
                                              repos = "http://cran.rstudio.com/")[[1]]

```


```{r}
update_freq <- updates_select %>% 
  group_by(Package) %>% 
  arrange(Date) %>%
  mutate(diff = c(NA,diff(Date)))

update_avg <- update_freq %>% 
  select(Package,diff) %>% 
  na.omit() %>% 
  group_by(Package) %>%
  summarise(avg=mean(diff))

 updates_select%>% 
  filter(Package=="Ecdat")

summary(update_freq$diff)

```







How to get the package updates:

```{r pkg-updates}
pkg_url <- "https://cran.r-project.org/web/packages/{pkg}/index.html"
pkg_archive <- "https://cran.r-project.org/src/contrib/Archive/{pkg}/"

pkgs_of_interest <- doe_pkgs[1:4]
pkg_updates <- map(pkgs_of_interest, function(pkg) {
    last_update <- read_html(glue(pkg_url)) %>% 
      html_table() %>% 
      .[[1]] %>% 
      filter(X1=="Published:") %>% 
      pull(X2) %>% 
      ymd()
      
    archive_dates <- tryCatch({ 
        read_html(glue(pkg_archive)) %>% 
          html_table() %>%
          .[[1]] %>% 
          pull(`Last modified`) %>% 
          ymd_hm() %>% 
          na.omit() %>% 
          as.Date()
      }, error = function(e) {
        NULL
      })
    c(archive_dates, last_update)
  })
names(pkg_updates) <- pkgs_of_interest

updates <- unlist(pkg_updates) %>% 
  enframe("package", "update") %>% 
  # unlist converts date to integers
  mutate(update = as.Date(update, origin = "1970-01-01"),
         # need to get rid of the numbers appended to pkg names
         package = str_extract(package, paste0(pkgs_of_interest, collapse="|"))) 

updates
```

